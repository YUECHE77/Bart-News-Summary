{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-17T09:39:46.295586Z",
     "start_time": "2024-07-17T09:39:40.021397Z"
    }
   },
   "source": [
    "import torch\n",
    "import datasets\n",
    "import lawrouge\n",
    "\n",
    "from typing import Dict\n",
    "from datasets import load_dataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import (Seq2SeqTrainingArguments, \n",
    "                          Seq2SeqTrainer, \n",
    "                          BartForConditionalGeneration)\n",
    "\n",
    "from transformers import BertTokenizer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "learning_rate = 1e-4\n",
    "\n",
    "max_input_length = 512  # max input length\n",
    "max_target_length = 128  # max output length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T09:40:18.571567Z",
     "start_time": "2024-07-17T09:40:18.567454Z"
    }
   },
   "id": "89cf89a44655f41f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "# load data\n",
    "dataset = load_dataset('json', data_files='dataset/nlpcc2017_clean.json', field='data')\n",
    "\n",
    "# load tokenizer -> Chinese bart uses bert's tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"pretrained_models/bart-base-chinese\")\n",
    "\n",
    "# load model\n",
    "model = BartForConditionalGeneration.from_pretrained(\"pretrained_models/bart-base-chinese\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T09:43:33.245860Z",
     "start_time": "2024-07-17T09:43:30.920538Z"
    }
   },
   "id": "985b822e7dfa4a91",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c8170ef4af54abeb87190302d518c26"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T09:43:38.681675Z",
     "start_time": "2024-07-17T09:43:38.677537Z"
    }
   },
   "id": "7a1495ae23556268",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['content', 'title'],\n",
       "        num_rows: 49944\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "def flatten(example):\n",
    "    return {\n",
    "        \"document\": example[\"content\"],\n",
    "        \"summary\": example[\"title\"],\n",
    "        \"id\":\"0\"\n",
    "    }\n",
    "\n",
    "# 将原始数据中的content和title转换为document和summary\n",
    "dataset = dataset[\"train\"].map(flatten, remove_columns=[\"title\", \"content\"])\n",
    "\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T09:44:18.475887Z",
     "start_time": "2024-07-17T09:44:16.871064Z"
    }
   },
   "id": "586e53142a92eb08",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/49944 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "236c264abb6e404e9a7ec91919ac4883"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['document', 'summary', 'id'],\n",
       "    num_rows: 49944\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset, test_dataset = dataset.train_test_split(test_size=0.1, shuffle=True, seed=42).values()\n",
    "\n",
    "train_dataset, valid_dataset = train_dataset.train_test_split(test_size=0.1, shuffle=True, seed=42).values()\n",
    "\n",
    "datasets = datasets.DatasetDict({\"train\":train_dataset, \"validation\": valid_dataset, \"test\":test_dataset})\n",
    "\n",
    "print(datasets)\n",
    "print()\n",
    "print(datasets[\"validation\"][7])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T09:45:00.245346Z",
     "start_time": "2024-07-17T09:45:00.210979Z"
    }
   },
   "id": "af50eacaa30d6773",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['document', 'summary', 'id'],\n",
      "        num_rows: 40454\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['document', 'summary', 'id'],\n",
      "        num_rows: 4495\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['document', 'summary', 'id'],\n",
      "        num_rows: 4995\n",
      "    })\n",
      "})\n",
      "\n",
      "{'document': 'A股市场的强势支撑新基金发行市场的持续火爆,尤其是二季度以来热度持续升温。据WIND数据显示,今年以来截止6月4日,共有8只基金的首募规模超过百亿,且全部诞生于二季度。这8只首募规模超百亿的基金包括易方达新丝路、易方达新常态、东方红中国优势、富国改革动力、中邮信息产业、景顺长城沪港深精选、工银瑞信丰盈回报、易方达并购重组,其中,易方达新常态、富国改革动力、中邮信息产业募集时间均只有一天,易方达新丝路募集时间则为2天。从基金公司角度看,上述8只基金中,有3只隶属于易方达基金。成立于5月28日的易方达新丝路首募规模达到286亿,创下本轮牛市中基金首募规模新纪录。而于5月29日结束募集的易方达并购重组发行规模则达到100.34亿。此前,易方达在4月30日成立的易方达新常态首募规模也达到146.63亿,成立一个月以来,其净值涨幅约为20%。仅凭这三只基金,易方达在二季度的规模就将增加约534亿元。WIND数据也显示,目前易方达公募资产规模为3151亿元,超过工银瑞信,仅次于天弘和华夏基金之后。东证资管发行的东方红中国优势成立于4月7日,首募规模为138.56亿元,排名第三。但成立近两个月以来其业绩表现并不出彩,截止6月4日净值涨幅仅有10.3%左右。由中邮基金经理任泽松管理的中邮信息产业在5月14日成立,首募规模达到126.02亿元。近两年,任泽松基金投资业绩出彩,他管理的中邮战略新兴产业在2013年净值增长率为80%,在同类基金中排名第一。富国改革动力、景顺长城沪港深精选、工银瑞信丰盈回报分别募得132.55亿元、110.12亿元、105.23亿元。除此之外,二季度另有5只基金首募规模在80亿以上。泰达宏利新起点首募92.17亿元,交银新回报、长盛转型升级主题、工银瑞信总回报、华商量化进取分别募得87.47亿元、85.83亿元、83.19亿元、80.98亿元。值得一提的是,在上述13只基金中,有10只为灵活配置型。', 'summary': '数据显示:今年以来,共有8只基金的首募规模超过百亿,且全部诞生于二季度;5只基金首募规模超80亿', 'id': '0'}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\"\n",
    "    document作为输入，summary作为标签\n",
    "    \"\"\"\n",
    "    model_inputs = tokenizer(examples[\"document\"], max_length=max_input_length, padding=\"max_length\", truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"summary\"], max_length=max_target_length, padding=\"max_length\", truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    return model_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T09:46:28.402785Z",
     "start_time": "2024-07-17T09:46:28.399340Z"
    }
   },
   "id": "28610796f278db14",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T09:49:26.419576Z",
     "start_time": "2024-07-17T09:46:44.367549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_datasets = datasets.map(preprocess_function, batched=True, remove_columns=[\"document\", \"summary\", \"id\"])\n",
    "\n",
    "print(tokenized_datasets[\"train\"][7].keys())\n",
    "print()\n",
    "print(tokenized_datasets[\"train\"][7])"
   ],
   "id": "51d62bbd967c6cb5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/40454 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9fa16960ae034242a36e47591f4bf051"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\EE541\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3921: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/4495 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c150e53e01b49b9867dd6e77ca484a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/4995 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2a36fa9363a464db5b763f7a6474617"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "\n",
      "{'input_ids': [101, 4941, 7178, 20466, 5967, 17342, 20448, 112, 20449, 17520, 21768, 11045, 18544, 113, 20449, 17520, 30832, 10936, 5100, 20815, 10771, 21764, 17342, 16224, 18458, 9582, 116, 21490, 10936, 116, 4941, 7730, 20815, 10771, 4907, 10185, 30901, 9051, 4941, 7730, 20815, 10771, 7385, 22859, 5369, 23195, 9485, 8318, 8505, 8909, 16022, 4915, 23660, 20849, 21995, 33868, 28097, 5085, 5722, 116, 10756, 10210, 7229, 10892, 17229, 16383, 14788, 5036, 5227, 10762, 5756, 5228, 10016, 7165, 23228, 8362, 9108, 15978, 20846, 19635, 20833, 3565, 5763, 5768, 15978, 20846, 5228, 10016, 5122, 6365, 7385, 8938, 11684, 10008, 6222, 10765, 21568, 3566, 18008, 12323, 116, 4941, 7730, 20815, 10771, 7385, 22859, 5369, 23195, 9485, 8318, 8505, 8909, 16022, 4915, 23660, 20849, 21995, 23671, 16413, 8922, 4907, 21471, 8321, 12435, 3566, 20815, 10771, 21764, 19916, 12543, 6423, 7229, 6222, 5036, 30901, 9051, 125, 11225, 30959, 10936, 5987, 116, 8442, 4941, 7730, 20815, 10771, 7385, 22859, 5369, 23195, 9485, 8318, 8505, 8909, 16022, 4915, 23660, 20849, 21995, 4907, 21471, 5959, 8938, 112, 6354, 113, 116, 9053, 21538, 9274, 6436, 7385, 22859, 5369, 23195, 9485, 8318, 8505, 8909, 16022, 5144, 6070, 21412, 21991, 15134, 20849, 13127, 11389, 16244, 7319, 7385, 8938, 6559, 4905, 17197, 5150, 4922, 12434, 21412, 23236, 4941, 15134, 7385, 8938, 5465, 10864, 3566, 6431, 10953, 116, 19916, 12543, 8938, 112, 6354, 113, 20815, 10771, 21764, 23016, 10218, 13841, 8909, 5241, 112, 8909, 16022, 113, 21500, 9101, 6365, 10953, 10185, 5110, 20849, 21995, 116, 15615, 5369, 20849, 21995, 4915, 12286, 4915, 14788, 3566, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [101, 4941, 7730, 20815, 10771, 4907, 10185, 5369, 23195, 10016, 8909, 16022, 4915, 23660, 20849, 21995, 33868, 28097, 5085, 5722, 116, 10756, 10210, 7229, 10892, 17229, 16383, 14788, 5036, 5227, 10762, 5756, 5228, 10016, 7165, 23228, 8362, 9108, 15978, 20846, 19635, 20833, 3565, 5763, 5768, 15978, 20846, 5228, 10016, 5122, 6365, 7385, 8938, 11684, 10008, 6222, 10765, 21568, 3566, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "def collate_fn(features: Dict):\n",
    "    batch_input_ids = torch.tensor([feature[\"input_ids\"] for feature in features], dtype=torch.long)\n",
    "    batch_attention_mask = torch.tensor([feature[\"attention_mask\"] for feature in features], dtype=torch.long)\n",
    "    batch_labels = torch.tensor([feature[\"labels\"] for feature in features], dtype=torch.long)\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": batch_input_ids,\n",
    "        \"attention_mask\": batch_attention_mask,\n",
    "        \"labels\": batch_labels\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T09:50:07.254316Z",
     "start_time": "2024-07-17T09:50:07.249848Z"
    }
   },
   "id": "6c46330e9e52b439",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "# 构建DataLoader来验证collate_fn\n",
    "dataloader = DataLoader(tokenized_datasets[\"test\"], shuffle=False, batch_size=4, collate_fn=collate_fn)\n",
    "batch = next(iter(dataloader))\n",
    "\n",
    "print(batch['input_ids'].shape)\n",
    "print(batch['attention_mask'].shape)\n",
    "print(batch['labels'].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T09:50:19.684287Z",
     "start_time": "2024-07-17T09:50:19.671224Z"
    }
   },
   "id": "708fe00ab50adf7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 128])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "output = model(**batch) # 验证前向传播\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T09:50:23.847175Z",
     "start_time": "2024-07-17T09:50:22.829340Z"
    }
   },
   "id": "2bc8b51f3c3e076b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2SeqLMOutput(loss=tensor(11.2249, grad_fn=<NllLossBackward0>), logits=tensor([[[-3.9331e+00, -3.5424e+00, -3.2559e+00,  ..., -6.7162e+00,\n",
      "          -2.7287e+00, -3.1338e+00],\n",
      "         [-6.9967e+00, -6.6629e+00, -6.6339e+00,  ..., -6.2032e+00,\n",
      "          -2.0105e+00, -3.7387e+00],\n",
      "         [-6.8036e+00, -6.7613e+00, -6.2919e+00,  ..., -5.2353e+00,\n",
      "          -9.0203e-01, -2.7664e+00],\n",
      "         ...,\n",
      "         [-3.0006e+00, -3.3891e+00, -2.7181e+00,  ..., -2.2596e+00,\n",
      "          -6.0266e-02, -8.1703e-01],\n",
      "         [-2.8956e+00, -3.3000e+00, -2.6745e+00,  ..., -2.1347e+00,\n",
      "          -3.7229e-02, -7.9668e-01],\n",
      "         [-2.9717e+00, -3.3836e+00, -2.7269e+00,  ..., -2.2174e+00,\n",
      "          -5.7367e-02, -7.8783e-01]],\n",
      "\n",
      "        [[-3.8879e+00, -3.3694e+00, -3.0851e+00,  ..., -5.5803e+00,\n",
      "          -3.1251e+00, -2.9459e+00],\n",
      "         [-7.0883e+00, -6.7556e+00, -6.4956e+00,  ..., -5.7501e+00,\n",
      "          -2.4619e+00, -4.4487e+00],\n",
      "         [-6.8258e+00, -6.7970e+00, -7.1764e+00,  ..., -6.4246e+00,\n",
      "          -3.8604e+00, -3.9191e+00],\n",
      "         ...,\n",
      "         [-2.3194e+00, -2.7686e+00, -2.3429e+00,  ..., -1.0516e+00,\n",
      "          -9.8985e-01, -3.0270e-02],\n",
      "         [-2.2069e+00, -2.6896e+00, -2.3320e+00,  ..., -8.0512e-01,\n",
      "          -9.8511e-01, -1.2470e-01],\n",
      "         [-2.2920e+00, -2.7597e+00, -2.3648e+00,  ..., -9.8897e-01,\n",
      "          -9.5242e-01,  5.8886e-03]],\n",
      "\n",
      "        [[-3.2308e+00, -3.1295e+00, -2.5622e+00,  ..., -5.7717e+00,\n",
      "          -3.8481e+00, -3.8644e+00],\n",
      "         [-6.7827e+00, -6.6897e+00, -6.7570e+00,  ..., -5.7864e+00,\n",
      "          -3.6585e+00, -5.3778e+00],\n",
      "         [-6.6997e+00, -6.6364e+00, -6.1250e+00,  ..., -4.9934e+00,\n",
      "          -3.9095e+00, -4.1731e+00],\n",
      "         ...,\n",
      "         [-2.2436e+00, -3.1460e+00, -2.8047e+00,  ..., -1.9717e+00,\n",
      "          -3.0190e-01, -1.6390e+00],\n",
      "         [-2.1508e+00, -3.0412e+00, -2.7640e+00,  ..., -1.8745e+00,\n",
      "          -3.5881e-01, -1.6175e+00],\n",
      "         [-2.2098e+00, -3.1217e+00, -2.7975e+00,  ..., -1.9462e+00,\n",
      "          -3.0302e-01, -1.5957e+00]],\n",
      "\n",
      "        [[-3.9130e+00, -3.5850e+00, -3.0930e+00,  ..., -4.3310e+00,\n",
      "          -1.8798e+00, -3.3259e+00],\n",
      "         [-6.5155e+00, -6.6405e+00, -6.7614e+00,  ..., -2.6243e+00,\n",
      "          -9.4125e-01, -3.8009e+00],\n",
      "         [-6.3899e+00, -6.5843e+00, -7.0998e+00,  ..., -5.8684e+00,\n",
      "          -2.4865e+00, -4.2221e+00],\n",
      "         ...,\n",
      "         [-2.7599e+00, -3.3328e+00, -3.2627e+00,  ..., -3.0956e-01,\n",
      "           9.5729e-01, -1.0641e+00],\n",
      "         [-2.6582e+00, -3.2240e+00, -3.2400e+00,  ..., -1.5057e-01,\n",
      "           8.5534e-01, -1.1575e+00],\n",
      "         [-2.7374e+00, -3.3213e+00, -3.2845e+00,  ..., -2.8216e-01,\n",
      "           9.8653e-01, -1.0254e+00]]], grad_fn=<AddBackward0>), past_key_values=None, decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[ 7.0506e-02,  3.0553e-02,  8.1859e-03,  ...,  2.0910e-02,\n",
      "          -8.0575e-02,  2.4946e-04],\n",
      "         [ 1.7009e-01,  4.8679e-01, -1.6235e-01,  ...,  2.4394e-01,\n",
      "          -3.3513e-01,  2.9007e-02],\n",
      "         [ 4.4832e-01,  3.3201e-01, -3.1771e-01,  ...,  4.4836e-01,\n",
      "           3.3551e-02, -1.4381e-01],\n",
      "         ...,\n",
      "         [-2.8862e-01,  9.0470e-01, -1.3269e-01,  ..., -2.4585e-01,\n",
      "           2.6278e-01, -3.7976e-01],\n",
      "         [-4.4625e-01,  8.4115e-01, -5.6040e-01,  ..., -4.2653e-01,\n",
      "           3.7224e-01,  4.9450e-02],\n",
      "         [-7.1833e-01,  3.6234e-01,  8.0207e-02,  ...,  5.5845e-02,\n",
      "           3.6762e-01,  5.1409e-02]],\n",
      "\n",
      "        [[ 8.4100e-02,  1.7880e-02,  2.1330e-03,  ...,  2.3730e-02,\n",
      "          -2.0403e-02,  2.6699e-02],\n",
      "         [ 1.8268e-01,  6.8925e-01,  1.2043e-01,  ...,  1.5876e-01,\n",
      "          -1.7940e-01, -1.6451e-01],\n",
      "         [-1.8350e-02,  2.7744e-01,  4.7959e-01,  ...,  1.1135e-01,\n",
      "          -3.7140e-01, -5.7301e-01],\n",
      "         ...,\n",
      "         [-2.1673e-02,  1.5419e-01,  1.0320e-01,  ..., -1.9577e-01,\n",
      "           7.6792e-02, -1.7677e-01],\n",
      "         [ 5.3303e-01,  8.9265e-02, -1.3337e-02,  ..., -1.2600e-01,\n",
      "           2.0348e-01, -6.1344e-01],\n",
      "         [ 2.7860e-01,  1.9343e-01,  1.3864e-01,  ..., -3.3992e-01,\n",
      "           3.2558e-01, -3.3640e-01]],\n",
      "\n",
      "        [[ 8.6938e-02,  2.6948e-02,  2.3873e-02,  ...,  1.6972e-03,\n",
      "          -8.3055e-02,  2.5976e-02],\n",
      "         [ 1.7667e-01,  5.4141e-01,  7.6927e-01,  ..., -1.1779e+00,\n",
      "          -2.7984e-01,  1.7122e-03],\n",
      "         [-2.7761e-01,  4.1558e-01, -2.7340e-01,  ..., -1.4603e+00,\n",
      "          -2.4212e-01,  6.4674e-01],\n",
      "         ...,\n",
      "         [-5.3361e-01,  4.1870e-01, -2.2303e-01,  ..., -6.8382e-01,\n",
      "           3.2565e-01, -8.3274e-02],\n",
      "         [-2.0175e-01,  7.1255e-01,  7.8477e-01,  ..., -9.2786e-01,\n",
      "           5.5074e-01,  5.0428e-01],\n",
      "         [-2.5379e-01,  1.8548e-01,  3.9816e-01,  ..., -2.3454e-01,\n",
      "           3.3642e-01,  3.2090e-02]],\n",
      "\n",
      "        [[ 6.9905e-02,  1.3109e-02,  2.5350e-02,  ...,  1.0031e-02,\n",
      "          -6.9601e-02,  1.3253e-02],\n",
      "         [ 4.0360e-01,  6.7613e-01, -2.6768e-01,  ..., -7.1235e-01,\n",
      "          -2.7238e-01,  2.1644e-02],\n",
      "         [ 1.5399e-01,  4.8379e-01, -3.2399e-01,  ..., -1.0352e+00,\n",
      "          -1.2270e-01, -2.4225e-01],\n",
      "         ...,\n",
      "         [-3.3091e-01,  1.7894e-01, -3.3274e-02,  ..., -1.7900e-01,\n",
      "           4.2682e-01,  2.2567e-01],\n",
      "         [-3.9818e-01,  6.5445e-01,  2.7054e-01,  ..., -9.1626e-01,\n",
      "           7.8279e-01, -1.3833e-01],\n",
      "         [ 2.1187e-01,  4.4697e-01,  2.1953e-01,  ..., -6.5733e-01,\n",
      "           6.3064e-01,  2.5781e-01]]], grad_fn=<NativeLayerNormBackward0>), encoder_hidden_states=None, encoder_attentions=None)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T09:50:25.115895Z",
     "start_time": "2024-07-17T09:50:25.108884Z"
    }
   },
   "id": "de937477ff6b5430",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqLMOutput(loss=tensor(11.2249, grad_fn=<NllLossBackward0>), logits=tensor([[[-3.9331e+00, -3.5424e+00, -3.2559e+00,  ..., -6.7162e+00,\n",
       "          -2.7287e+00, -3.1338e+00],\n",
       "         [-6.9967e+00, -6.6629e+00, -6.6339e+00,  ..., -6.2032e+00,\n",
       "          -2.0105e+00, -3.7387e+00],\n",
       "         [-6.8036e+00, -6.7613e+00, -6.2919e+00,  ..., -5.2353e+00,\n",
       "          -9.0203e-01, -2.7664e+00],\n",
       "         ...,\n",
       "         [-3.0006e+00, -3.3891e+00, -2.7181e+00,  ..., -2.2596e+00,\n",
       "          -6.0266e-02, -8.1703e-01],\n",
       "         [-2.8956e+00, -3.3000e+00, -2.6745e+00,  ..., -2.1347e+00,\n",
       "          -3.7229e-02, -7.9668e-01],\n",
       "         [-2.9717e+00, -3.3836e+00, -2.7269e+00,  ..., -2.2174e+00,\n",
       "          -5.7367e-02, -7.8783e-01]],\n",
       "\n",
       "        [[-3.8879e+00, -3.3694e+00, -3.0851e+00,  ..., -5.5803e+00,\n",
       "          -3.1251e+00, -2.9459e+00],\n",
       "         [-7.0883e+00, -6.7556e+00, -6.4956e+00,  ..., -5.7501e+00,\n",
       "          -2.4619e+00, -4.4487e+00],\n",
       "         [-6.8258e+00, -6.7970e+00, -7.1764e+00,  ..., -6.4246e+00,\n",
       "          -3.8604e+00, -3.9191e+00],\n",
       "         ...,\n",
       "         [-2.3194e+00, -2.7686e+00, -2.3429e+00,  ..., -1.0516e+00,\n",
       "          -9.8985e-01, -3.0270e-02],\n",
       "         [-2.2069e+00, -2.6896e+00, -2.3320e+00,  ..., -8.0512e-01,\n",
       "          -9.8511e-01, -1.2470e-01],\n",
       "         [-2.2920e+00, -2.7597e+00, -2.3648e+00,  ..., -9.8897e-01,\n",
       "          -9.5242e-01,  5.8886e-03]],\n",
       "\n",
       "        [[-3.2308e+00, -3.1295e+00, -2.5622e+00,  ..., -5.7717e+00,\n",
       "          -3.8481e+00, -3.8644e+00],\n",
       "         [-6.7827e+00, -6.6897e+00, -6.7570e+00,  ..., -5.7864e+00,\n",
       "          -3.6585e+00, -5.3778e+00],\n",
       "         [-6.6997e+00, -6.6364e+00, -6.1250e+00,  ..., -4.9934e+00,\n",
       "          -3.9095e+00, -4.1731e+00],\n",
       "         ...,\n",
       "         [-2.2436e+00, -3.1460e+00, -2.8047e+00,  ..., -1.9717e+00,\n",
       "          -3.0190e-01, -1.6390e+00],\n",
       "         [-2.1508e+00, -3.0412e+00, -2.7640e+00,  ..., -1.8745e+00,\n",
       "          -3.5881e-01, -1.6175e+00],\n",
       "         [-2.2098e+00, -3.1217e+00, -2.7975e+00,  ..., -1.9462e+00,\n",
       "          -3.0302e-01, -1.5957e+00]],\n",
       "\n",
       "        [[-3.9130e+00, -3.5850e+00, -3.0930e+00,  ..., -4.3310e+00,\n",
       "          -1.8798e+00, -3.3259e+00],\n",
       "         [-6.5155e+00, -6.6405e+00, -6.7614e+00,  ..., -2.6243e+00,\n",
       "          -9.4125e-01, -3.8009e+00],\n",
       "         [-6.3899e+00, -6.5843e+00, -7.0998e+00,  ..., -5.8684e+00,\n",
       "          -2.4865e+00, -4.2221e+00],\n",
       "         ...,\n",
       "         [-2.7599e+00, -3.3328e+00, -3.2627e+00,  ..., -3.0956e-01,\n",
       "           9.5729e-01, -1.0641e+00],\n",
       "         [-2.6582e+00, -3.2240e+00, -3.2400e+00,  ..., -1.5057e-01,\n",
       "           8.5534e-01, -1.1575e+00],\n",
       "         [-2.7374e+00, -3.3213e+00, -3.2845e+00,  ..., -2.8216e-01,\n",
       "           9.8653e-01, -1.0254e+00]]], grad_fn=<AddBackward0>), past_key_values=None, decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[ 7.0506e-02,  3.0553e-02,  8.1859e-03,  ...,  2.0910e-02,\n",
       "          -8.0575e-02,  2.4946e-04],\n",
       "         [ 1.7009e-01,  4.8679e-01, -1.6235e-01,  ...,  2.4394e-01,\n",
       "          -3.3513e-01,  2.9007e-02],\n",
       "         [ 4.4832e-01,  3.3201e-01, -3.1771e-01,  ...,  4.4836e-01,\n",
       "           3.3551e-02, -1.4381e-01],\n",
       "         ...,\n",
       "         [-2.8862e-01,  9.0470e-01, -1.3269e-01,  ..., -2.4585e-01,\n",
       "           2.6278e-01, -3.7976e-01],\n",
       "         [-4.4625e-01,  8.4115e-01, -5.6040e-01,  ..., -4.2653e-01,\n",
       "           3.7224e-01,  4.9450e-02],\n",
       "         [-7.1833e-01,  3.6234e-01,  8.0207e-02,  ...,  5.5845e-02,\n",
       "           3.6762e-01,  5.1409e-02]],\n",
       "\n",
       "        [[ 8.4100e-02,  1.7880e-02,  2.1330e-03,  ...,  2.3730e-02,\n",
       "          -2.0403e-02,  2.6699e-02],\n",
       "         [ 1.8268e-01,  6.8925e-01,  1.2043e-01,  ...,  1.5876e-01,\n",
       "          -1.7940e-01, -1.6451e-01],\n",
       "         [-1.8350e-02,  2.7744e-01,  4.7959e-01,  ...,  1.1135e-01,\n",
       "          -3.7140e-01, -5.7301e-01],\n",
       "         ...,\n",
       "         [-2.1673e-02,  1.5419e-01,  1.0320e-01,  ..., -1.9577e-01,\n",
       "           7.6792e-02, -1.7677e-01],\n",
       "         [ 5.3303e-01,  8.9265e-02, -1.3337e-02,  ..., -1.2600e-01,\n",
       "           2.0348e-01, -6.1344e-01],\n",
       "         [ 2.7860e-01,  1.9343e-01,  1.3864e-01,  ..., -3.3992e-01,\n",
       "           3.2558e-01, -3.3640e-01]],\n",
       "\n",
       "        [[ 8.6938e-02,  2.6948e-02,  2.3873e-02,  ...,  1.6972e-03,\n",
       "          -8.3055e-02,  2.5976e-02],\n",
       "         [ 1.7667e-01,  5.4141e-01,  7.6927e-01,  ..., -1.1779e+00,\n",
       "          -2.7984e-01,  1.7122e-03],\n",
       "         [-2.7761e-01,  4.1558e-01, -2.7340e-01,  ..., -1.4603e+00,\n",
       "          -2.4212e-01,  6.4674e-01],\n",
       "         ...,\n",
       "         [-5.3361e-01,  4.1870e-01, -2.2303e-01,  ..., -6.8382e-01,\n",
       "           3.2565e-01, -8.3274e-02],\n",
       "         [-2.0175e-01,  7.1255e-01,  7.8477e-01,  ..., -9.2786e-01,\n",
       "           5.5074e-01,  5.0428e-01],\n",
       "         [-2.5379e-01,  1.8548e-01,  3.9816e-01,  ..., -2.3454e-01,\n",
       "           3.3642e-01,  3.2090e-02]],\n",
       "\n",
       "        [[ 6.9905e-02,  1.3109e-02,  2.5350e-02,  ...,  1.0031e-02,\n",
       "          -6.9601e-02,  1.3253e-02],\n",
       "         [ 4.0360e-01,  6.7613e-01, -2.6768e-01,  ..., -7.1235e-01,\n",
       "          -2.7238e-01,  2.1644e-02],\n",
       "         [ 1.5399e-01,  4.8379e-01, -3.2399e-01,  ..., -1.0352e+00,\n",
       "          -1.2270e-01, -2.4225e-01],\n",
       "         ...,\n",
       "         [-3.3091e-01,  1.7894e-01, -3.3274e-02,  ..., -1.7900e-01,\n",
       "           4.2682e-01,  2.2567e-01],\n",
       "         [-3.9818e-01,  6.5445e-01,  2.7054e-01,  ..., -9.1626e-01,\n",
       "           7.8279e-01, -1.3833e-01],\n",
       "         [ 2.1187e-01,  4.4697e-01,  2.1953e-01,  ..., -6.5733e-01,\n",
       "           6.3064e-01,  2.5781e-01]]], grad_fn=<NativeLayerNormBackward0>), encoder_hidden_states=None, encoder_attentions=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # 将预测的 id 转换为 token\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # 将标签转换为 token\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # 去掉解码后的空格\n",
    "    decoded_preds = [\"\".join(pred.split()) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\".join(label.split()) for label in decoded_labels]\n",
    "    \n",
    "    # 计算 ROUGE\n",
    "    rouge = lawrouge.Rouge()\n",
    "    result = rouge.get_scores(decoded_preds, decoded_labels, avg=True)\n",
    "    result = {\n",
    "        'rouge-1': result['rouge-1']['f'],\n",
    "        'rouge-2': result['rouge-2']['f'],\n",
    "        'rouge-l': result['rouge-l']['f']\n",
    "    }\n",
    "    \n",
    "    # 将结果转换为百分比\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    \n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T09:50:50.598277Z",
     "start_time": "2024-07-17T09:50:50.594472Z"
    }
   },
   "id": "91f994a588283b26",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "# How to use the metrics function\n",
    "predictions = ['我今天的午餐是牛肉饼', '我明天的晚餐是汉堡']\n",
    "targets = ['我今天中午吃牛肉饼', '我明天晚上吃汉堡']\n",
    "\n",
    "# 将示例数据进行tokenize\n",
    "predictions_tokenized = tokenizer(predictions, max_length=max_target_length, padding=True, truncation=True, return_tensors='pt')\n",
    "targets_tokenized = tokenizer(targets, max_length=max_target_length, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# 模拟 eval_pred 格式\n",
    "eval_pred = (predictions_tokenized['input_ids'], targets_tokenized['input_ids'])\n",
    "\n",
    "# 计算评估指标\n",
    "results = compute_metrics(eval_pred)\n",
    "\n",
    "# 输出结果\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T09:51:12.369851Z",
     "start_time": "2024-07-17T09:51:12.364093Z"
    }
   },
   "id": "650bdeb289a616dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': 72.13622241177428, 'rouge-2': 43.52941126668205, 'rouge-l': 72.13622241177428}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "# 设置训练参数\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"/content/results\", # 模型保存路径\n",
    "    num_train_epochs=epochs,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.0001,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir=\"/content/logs\",\n",
    "    logging_steps=2000,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=2000,  # 设置评估步数\n",
    "    save_steps=2000,  # 设置保存步数\n",
    "    save_total_limit=3,\n",
    "    generation_max_length=max_target_length, # 生成的最大长度\n",
    "    generation_num_beams=3, # beam search -> 1 is greedy search\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"rouge-1\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T09:51:27.209882Z",
     "start_time": "2024-07-17T09:51:25.751940Z"
    }
   },
   "id": "26ee21f0808969f0",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=collate_fn,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T09:51:29.181316Z",
     "start_time": "2024-07-17T09:51:27.884026Z"
    }
   },
   "id": "ac8de1773ad720f8",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ae129ee094bf98c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 打印验证集上的结果\n",
    "print(trainer.evaluate(tokenized_datasets[\"validation\"]))\n",
    "# 打印测试集上的结果\n",
    "print(trainer.evaluate(tokenized_datasets[\"test\"]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5109ccaf590fdd7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存最终模型\n",
    "trainer.save_model(\"results/best\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af1e5c7bca6fbdc4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 加载模型并测试"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b6e729395b73b"
  },
  {
   "cell_type": "code",
   "source": [
    "model = BartForConditionalGeneration.from_pretrained('logs/best')\n",
    "tokenizer = BertTokenizer.from_pretrained(\"logs/best\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'The device you are using is {device}')\n",
    "\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T09:51:57.157389Z",
     "start_time": "2024-07-17T09:51:55.837899Z"
    }
   },
   "id": "a24f2e99a73d9cb2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device you are using is cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(51271, 768, padding_idx=0)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(51271, 768, padding_idx=0)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(51271, 768, padding_idx=0)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=51271, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "def predict(text_, model_, tokenizer_):\n",
    "    tokenized_text = tokenizer_(text_, padding=True, truncation=True, max_length=max_target_length, return_tensors='pt')\n",
    "    \n",
    "    input_ids = tokenized_text['input_ids'].to(model_.device)\n",
    "    attention_mask = tokenized_text['attention_mask'].to(model_.device)\n",
    "    \n",
    "    output_ = model_.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=max_target_length)\n",
    "    \n",
    "    result_ = tokenizer_.decode(token_ids=output_[0], skip_special_tokens=True).replace(' ', '')\n",
    "    \n",
    "    return result_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbfa66175ba04bf5",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "text = '中新网6月11日电据外媒11日报道,在美国,由于私人飞机的价格太贵,学习开飞机的人有所减少,美国数百个小机场已经关闭,部分机场被改为赛车场或是农田。艾奥瓦州的一位官员说,当地的一座小机场已不再使用,因此地方议会决定将其关闭,机场跑道被改成赛车场。在美国,许多小城镇自上世纪20年代以来开始兴建机场,二战后许多军用飞机的驾驶员退役,但回乡后仍希望继续飞行,因此小机场的规模得到扩大。美国有私人飞机飞行执照的人在上世纪80年代初最多,但如今已降至18.8万人,使得全国数百个小机场关闭。专家指出,数十年前,买一架新的小飞机约需1.3万美元,如今需要25万美元以上。而且飞机还要使用特种航油、买保险、维修、建机库和停机坪。在小飞机的驾驶员人数下降之际,美国商业飞行的旅客却在增多,预计今年的航空旅客将创下纪录。但如今,航空飞行的魅力对许多人而言已不如过去,商业航班经常晚点,一位老飞行员表示,美国民众乘飞机旅行的兴趣已经大大减少。'\n",
    "\n",
    "result = predict(text, model, tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T09:53:14.986413Z",
     "start_time": "2024-07-17T09:53:11.395662Z"
    }
   },
   "id": "6ecc5c0057c1c1fc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\EE541\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:587: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "# ground truth: 由于私人飞机价格昂贵,学习飞行技术人数减少,美国数百个小机场已经关闭,部分机场被改为赛车场或是农田。\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T09:53:17.006084Z",
     "start_time": "2024-07-17T09:53:17.003263Z"
    }
   },
   "id": "a6b50dfed62ad7e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数百个小机场已经关闭,部分机场被改为赛车场或是农田;由于私人飞机价格昂贵,学习开飞机的人数减少。\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "143a8cb40a09c1bd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
